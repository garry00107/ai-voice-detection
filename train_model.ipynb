{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# AI Voice Detector Training\n",
                "Run this notebook on Google Colab (Runtime > Change runtime type > T4 GPU) to train your model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install kagglehub transformers torch librosa scikit-learn joblib numpy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import kagglehub\n",
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "# Download dataset\n",
                "path = kagglehub.dataset_download(\"kambingbersayaphitam/speech-dataset-of-human-and-ai-generated-voices\")\n",
                "DATASET_DIR = Path(path)\n",
                "print(\"Dataset downloaded to:\", DATASET_DIR)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import librosa\n",
                "import numpy as np\n",
                "from transformers import Wav2Vec2Processor, Wav2Vec2Model\n",
                "import joblib\n",
                "\n",
                "# Check for GPU\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "# Load Model\n",
                "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base\")\n",
                "model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base\").to(device)\n",
                "\n",
                "def extract_features(filepath):\n",
                "    try:\n",
                "        # Load audio (resample to 16k for Wav2Vec2)\n",
                "        audio, sr = librosa.load(filepath, sr=16000)\n",
                "        \n",
                "        # Tokenize\n",
                "        inputs = processor(audio, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
                "        input_values = inputs.input_values.to(device)\n",
                "        \n",
                "        # Extract\n",
                "        with torch.no_grad():\n",
                "            outputs = model(input_values)\n",
                "            hidden_states = outputs.last_hidden_state\n",
                "            # Mean pooling\n",
                "            embeddings = hidden_states.mean(dim=1)\n",
                "            \n",
                "        return embeddings.cpu().numpy()[0]\n",
                "    except Exception as e:\n",
                "        print(f\"Error: {e}\")\n",
                "        return None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare Data\n",
                "real_files = list(DATASET_DIR.rglob(\"*Real*/*.wav\")) + list(DATASET_DIR.rglob(\"*Real*/*.mp3\"))\n",
                "fake_files = list(DATASET_DIR.rglob(\"*Fake*/*.wav\")) + list(DATASET_DIR.rglob(\"*Fake*/*.mp3\"))\n",
                "\n",
                "print(f\"Found {len(real_files)} Real samples\")\n",
                "print(f\"Found {len(fake_files)} Fake samples\")\n",
                "\n",
                "X = []\n",
                "y = []\n",
                "\n",
                "print(\"Processing Real files...\")\n",
                "for f in real_files:\n",
                "    emb = extract_features(f)\n",
                "    if emb is not None:\n",
                "        X.append(emb)\n",
                "        y.append(0) # HUMAN\n",
                "\n",
                "print(\"Processing Fake files...\")\n",
                "for f in fake_files:\n",
                "    emb = extract_features(f)\n",
                "    if emb is not None:\n",
                "        X.append(emb)\n",
                "        y.append(1) # AI\n",
                "\n",
                "X = np.array(X)\n",
                "y = np.array(y)\n",
                "print(f\"Final dataset shape: {X.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.model_selection import cross_val_score\n",
                "\n",
                "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "\n",
                "# CV Score\n",
                "scores = cross_val_score(clf, X, y, cv=5)\n",
                "print(f\"Accuracy: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
                "\n",
                "# Train full model\n",
                "clf.fit(X, y)\n",
                "\n",
                "# Save\n",
                "output_data = {\n",
                "    'model': clf,\n",
                "    'type': 'rf_wav2vec2',\n",
                "    'version': '1.0'\n",
                "}\n",
                "joblib.dump(output_data, \"trained_model.joblib\")\n",
                "print(\"Model saved as trained_model.joblib - Download this file!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}